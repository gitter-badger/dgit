#!/usr/bin/env python 
"""
Tool to manage growing number of datasets and versions 
"""

import os, sys, tempfile
import json
import getpass 
import traceback 
import click 
from distutils.spawn import find_executable
from dgitcore import plugins 
from dgitcore import config, datasets, helper 

# 
thisdir=os.path.realpath(os.path.dirname(__file__))


@click.group()
def process(standlone_mode=False):
    """
    git wrapper for datasets
    """
    pass

@process.command('config')
@click.argument('action',
                type=click.Choice(['update', 'init', 'show']))
@click.option('-g',
              "--globalvar",
              nargs=2, 
              multiple=1,
              type=click.Tuple([str,str]),
              help="Update profile variables")
def profile(action, globalvar): 
    """
    Create configuration file (~/.dgit.ini) 
    """
    if action in ["update", "init"]:
        config.update(globalvar)
    elif action == "show":
        config.init(globalvar, show=True)


@process.command('init', context_settings=dict(
    ignore_unknown_options=True,
))
@click.argument('dataset')
@click.option("--setup",
              type=click.Choice(['git+s3', 'git']),
              default='git+s3',
              help="What is the backend for this repo")
@click.option("--force",
              default=False,
              is_flag=True,
              help="Force overwriting the directory")
def init(dataset, setup, force): 
    """
    Bootstrap a new dataset (a git repo+s3 backup)
    
    Example: 

    # Create a local repo with s3 backend 
    dgit init --setup git+s3 pingali/hello 

    # Create a local repo with no backends 
    dgit init --setup git pingali/hello 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    # Get the command that must be run 
    datasets.init(username, dataset, setup, force)

@process.command('commit', 
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def commit(dataset, args): 
    """
    Commit the changes made to a dataset 
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        print("Dataset must be specified or provided as a default")
        return

    # Get the command that must be run 
    datasets.commit(username, dataset, list(args))

@process.command('post')
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to post")
def post(dataset): 
    """
    Post to metadata server
    """
    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        print("Dataset must be specified or provided as a default")
        return

    # Get the command that must be run 
    datasets.post(username, dataset)

@process.command('list')
@click.option('--remote', '-r',
              is_flag=True, 
              default=False,
              help="List remote repos available")
def list_repos(remote): 
    """
    List datasets
    """
    datasets.list_repos(remote)

@process.command('sh',
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to post")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def shcmd(dataset, args): 
    """
    Post to metadata server
    """
    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        print("Dataset must be specified or provided as a default")
        return

    # Get the command that must be run 
    datasets.shellcmd(username, dataset, list(args))

@process.command('log',
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to check log")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def log(dataset, args): 
    """
    Commit the changes made to a dataset 
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    # Get the command that must be run 
    datasets.log(username, dataset, list(args))

@process.command('default')
@click.argument('action',
              type=click.Choice(['clear', 'get', 'set']),
              default="get")
@click.option('--dataset', '-d',
              default=None,
              help='Dataset')
def default(action,dataset):
    """
    Set the default dataset
    """
    if action == 'set': 
        if dataset is not None: 
            config.set_default_dataset(dataset)
        else: 
            print("Dataset must be specified for set")            
    elif action == "clear": 
        config.clear_default_dataset()
    elif action == "get": 
        dataset = config.get_default_dataset()
        print("Default dataset:", dataset)


@process.command('rm',
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.argument('dataset')
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def rm(dataset, args): 
    """
    Commit the changes made to a dataset 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    if len(args) == 0: 
        print("No files specified to remove") 
        return 

    # Get the command that must be run 
    result = datasets.delete(username, dataset, list(args))
    if 'message' in result: 
        print(result['message'])


@process.command('add-files', context_settings=dict(
    ignore_unknown_options=True,
))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
@click.option("--targetdir", '-t', 
              default=".",
              help="Directory in repo")
@click.option("--include", '-i', 
              multiple=True,
              help="File patterns to include")
@click.option("--generator/--no-generator",
              default=False,
              help="Generator script")
@click.option("--script/--no-script",
              default=False,
              help="Mark the script file as executable")
@click.option("--source",
              default=False,
              help="Source of the data")
@click.option("--execute/--no-execute",
              default=False,
              help="Execute the filename specified")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def add(dataset, targetdir, args, execute, 
        generator, source, include, script):
    """
    Add files to the repo
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    if generator and execute: 
        print("Generator and execute are mutually exclusive") 
        return 
        
    if execute and len(include) == 0: 
        print("Files to be included must be specified")
        return

    # Extract the correct dataset name
    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    args = helper.clean_args(args, execute) 
    if args is None: 
        return 

    # Cleanup includes 
    includes = []
    for i in include:
        includes.extend(i.split(","))

    datasets.add(username=username, 
                 dataset=dataset, 
                 args=args, 
                 execute=execute, 
                 source=source,
                 script=script,
                 generator=generator, 
                 targetdir=targetdir, 
                 includes=includes)

@process.command('add-preview',
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
@click.option("--size", '-s', 
              default=512, 
              help="Size of snippet to include")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def preview(dataset, size, args):
    """
    Add files preview from files into metadata 
    """
    if dataset is None: 
        dataset = config.get_default_dataset() 

    # Extract the correct dataset name
    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    datasets.add_preview(username, dataset, size, list(args))


@process.command('validate')
@click.option('--dataset', '-d',
              default=None,
              help="Dataset")
def validate(dataset): 
    """
    Check the integrity of a dataset
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.validate(username, dataset) 

@process.command()
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
def stash(dataset): 
    """
    Trash all the changes for a given dataset
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.stash(username, dataset) 
    return 

@process.command('diff', 
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def diff(dataset, args): 
    """
    Show changes
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.diff(username, dataset, list(args))
    return 


@process.command('status',
                 context_settings=dict(
                     ignore_unknown_options=True,
                     allow_extra_args=True
                 ))
@click.option("--dataset", '-d', default=None)
@click.option("--details/--no-details", 
              is_flag=True,
              default=False,
              help="Show details")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def status(dataset, details, args): 
    """
    Show all the datasets available
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset) 
    
    # username and dataset could still be None 
    datasets.status(username, dataset, details, list(args))
 
    return 

@process.command()
@click.argument("url")
def clone(url): 
    """
    Clone a git URL 
    """
    datasets.clone(url) 
    return 


@process.command()
@click.argument("op",
                type=click.Choice(['add', 'rm', 'rename', 'show']))
@click.argument("dataset")
@click.argument("shortname")
@click.argument("url")
def remote(op, dataset, shortname, url): 
    """
    Manage remote 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return
    
    
    # git remote add pb https://github.com/paulboone/ticgit
    datasets.remote(op, username, dataset, shortname, url) 
    return 


@process.command()
@click.argument('dataset')
def drop(dataset): 
    """
    Drop a dataset
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.drop(username, dataset)

@process.command()
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
def push(dataset): 
    """
    Upload a dataset to origin (github/s3/local)
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.push(username, dataset) 



@process.command('plugins')
@click.argument('action',
                type=click.Choice(['list', 'show', 'new']),
                default='show')
@click.option('--what',
                type=click.Choice(['backend', 'instrumentation', 'repomanager']))
@click.option('--name')              
@click.option('--version')              
def plugin_cmd(action, what, name, version): 
    """
    Plugin management
    """
    if action == "show":
        plugins.show(what, name, version, details=True)
    elif action == "list":
        plugins.show(what, name, version, details=False)
    elif action == "new":
        plugins.generate(what, name, version)

if __name__ == "__main__": 
    
    plugins.load() 
    try: 
        config.init()
        process() 
    except Exception as e: 
        traceback.print_exc() 
    plugins.close() 
