#!/usr/bin/env python 
"""
Tool to manage growing number of datasets and versions 
"""

import os, sys, tempfile
import json
import getpass 
import traceback 
import click 
from distutils.spawn import find_executable
from dgitcore import plugins 
from dgitcore import config, datasets, helper 

# 
thisdir=os.path.realpath(os.path.dirname(__file__))


@click.group()
def process(standlone_mode=False):
    """
    git wrapper for datasets
    """
    pass

@process.command('config')
@click.argument('action',
                type=click.Choice(['update', 'init', 'show']))
@click.option('-g',
              "--globalvar",
              nargs=2, 
              multiple=1,
              type=click.Tuple([str,str]),
              help="Update profile variables")
def profile(action, globalvar): 
    """
    Create configuration file (~/.dgit.ini) 
    """
    if action in ["update", "init"]:
        config.update(globalvar)
    elif action == "show":
        config.init(globalvar, show=True)



@process.command('init', context_settings=dict(
    ignore_unknown_options=True,
))
@click.argument('dataset')
@click.option("--setup",
              type=click.Choice(['git+s3', 'git']),
              default='git+s3',
              help="What is the backend for this repo")
@click.option("--force",
              default=False,
              is_flag=True,
              help="Force overwriting the directory")
def init(dataset, setup, force): 
    """
    Bootstrap a new dataset (a git repo+s3 backup)
    
    Example: 

    # Create a local repo with s3 backend 
    dgit init --setup git+s3 pingali/hello 

    # Create a local repo with no backends 
    dgit init --setup git pingali/hello 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    # Get the command that must be run 
    datasets.init(username, dataset, setup, force)

@process.command('commit')
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
@click.option("--message", '-m',
              help="Commit message")
def commit(dataset, message): 
    """
    Commit the changes made to a dataset 
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        print("Dataset must be specified or provided as a default")
        return

    if message is None: 
        print("A commit message is necessary") 
        return 

    # Get the command that must be run 
    datasets.commit(username, dataset, message)

@process.command('post')
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
def post(dataset): 
    """
    Post to metadata server
    """
    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        print("Dataset must be specified or provided as a default")
        return

    # Get the command that must be run 
    datasets.post(username, dataset)

@process.command('log')
@click.argument('dataset')
def log(dataset): 
    """
    Commit the changes made to a dataset 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    # Get the command that must be run 
    datasets.log(username, dataset)

@process.command('default')
@click.option('--dataset', '-d',
              default=None,
              help='Dataset')
@click.option('--action','-a',
              type=click.Choice(['clear', 'get', 'set']),
              default="get",
              help="Action on default")
def default(dataset, action):
    """
    Set the default dataset
    """
    if action == 'set': 
        if dataset is not None: 
            config.set_default_dataset(dataset)
        else: 
            print("Dataset must be specified for set")            
    elif action == "clear": 
        config.clear_default_dataset()
    elif action == "get": 
        dataset = config.get_default_dataset()
        print("Default dataset:", dataset)


@process.command('rm')
@click.argument('dataset')
@click.option('--force',
              help='Force deletion of the files')
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def rm(dataset, force, args): 
    """
    Commit the changes made to a dataset 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    if len(args) == 0: 
        print("No files specified to remove") 
        return 

    # Get the command that must be run 
    result = datasets.delete(username, dataset, force, args)
    if 'message' in result: 
        print(result['message'])


@process.command('add', context_settings=dict(
    ignore_unknown_options=True,
))
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
@click.option("--targetdir", '-t', 
              default=".",
              help="Directory in repo")
@click.option("--include", '-i', 
              multiple=True,
              help="File patterns to include")
@click.option("--generator/--no-generator",
              default=False,
              help="Generator script")
@click.option("--script",
              default=False,
              help="Mark the script file as executable")
@click.option("--execute/--no-execute",
              default=False,
              help="Execute the filename specified")
@click.argument('args', nargs=-1, type=click.UNPROCESSED)
def add(dataset, targetdir, args, execute, 
        generator, include, script):
    """
    Add content to a dataset 
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    if generator and execute: 
        print("Generator and execute are mutually exclusive") 
        return 
        
    if execute and len(include) == 0: 
        print("Files to be included must be specified")
        return


    # Extract the correct dataset name
    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None: 
        return

    args = helper.clean_args(args, execute) 
    if args is None: 
        return 

    # Cleanup includes 
    includes = []
    for i in include:
        includes.extend(i.split(","))

    datasets.add(username, dataset, 
                 args, 
                 execute, generator, 
                 targetdir, 
                 includes, script) 


@process.command()
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
def stash(dataset): 
    """
    Trash all the changes for a given dataset
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.stash(username, dataset) 
    return 


@process.command('status')
@click.option("--dataset", '-d', default=None)
@click.option("--details/--no-details", 
              is_flag=True,
              default=False,
              help="Show details")
def status(dataset, details): 
    """
    Show all the datasets available
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    print("dataset = ", dataset) 

    (username, dataset) = helper.parse_dataset_name(dataset) 
    
    # username and dataset could still be None 
    datasets.status(username, dataset, details)
 
    return 

@process.command()
@click.argument("url")
def clone(url): 
    """
    Clone a git URL 
    """
    datasets.clone(url) 
    return 


@process.command()
@click.argument("op",
                type=click.Choice(['add', 'rm', 'rename', 'show']))
@click.argument("dataset")
@click.argument("shortname")
@click.argument("url")
def remote(op, dataset, shortname, url): 
    """
    Manage remote 
    """

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return
    
    
    # git remote add pb https://github.com/paulboone/ticgit
    datasets.remote(op, username, dataset, shortname, url) 
    return 


@process.command()
@click.argument('name')
def drop(name): 
    """
    Drop a dataset
    """
    datasets.drop(name)

@process.command()
@click.option('--dataset', '-d',
              default=None,
              help="Dataset to stash")
def push(dataset): 
    """
    Upload a dataset to origin (github/s3/local)
    """

    if dataset is None: 
        dataset = config.get_default_dataset() 

    (username, dataset) = helper.parse_dataset_name(dataset)    
    if dataset is None or username is None: 
        print("Could not find the dataset. Please specify exact repo to be stashed")
        return

    datasets.push(username, dataset) 



@process.command('plugins')
@click.argument('action',
                type=click.Choice(['list', 'show', 'new']),
                default='show')
@click.option('--what',
                type=click.Choice(['backend', 'instrumentation', 'repomanager']))
@click.option('--name')              
@click.option('--version')              
def plugin_cmd(action, what, name, version): 
    """
    Plugin management
    """
    if action == "show":
        plugins.show(what, name, version, details=True)
    elif action == "list":
        plugins.show(what, name, version, details=False)
    elif action == "new":
        plugins.generate(what, name, version)

if __name__ == "__main__": 
    
    plugins.load() 
    try: 
        config.init()
        process() 
    except Exception as e: 
        traceback.print_exc() 
    plugins.close() 
