dgit - Lightweight "Git Wrapper for Datasets"
=============================================

*Note: Code is still pre-alpha. It is being cleanedup and stabilized. Not yet ready for daily use.* 

dgit is an application on top of git. The application uses git for
version management but structures the repositories, content, and
interface to suit data management tasks. 

A lot of data-scientists' time goes towards generating, shaping, and
using datasets. dgit enables organizing and using datasets with
minimal effort. dgit leverages the versioning capability from git. Git
can be replaced with other versioning backends such as instabase (as
and when it is released) as needed.

dgit is agnostic to form and content of the datasets and
post-processing scripts. It tries to adher to `best available dataset
standards <http://dataprotocols.org>`_

Read `documentation <https://dgit.readthedocs.org>`_ 

Contents:

* Usage
    1. `Command`_
    2. `Tutorial`_
    3. `Plugins`_
    4. `Security and Privacy`_
* Background
    1. `Dataset Management Problem`_ 
    2. `Usecase`_

Usage
=====

A major objective of dgit is simplicity. Using dgit should not more
complex than git itself. And if you dont use it, there is no cost. 

Command
--------

Setup 
::
   
    # Dependencies (Ubuntu commands for lxml dependency) 
    $ sudo apt-get install libxml2-dev libxslt1-dev python-dev
    
    # 
    $ pip install dgit 

    # Add alias for ease of use (note the single quote for bang operator) 
    $ git config --global alias.data '!dgit'

Usage
::
    $ dgit 
    Usage: dgit [OPTIONS] COMMAND [ARGS]...
    
      git wrapper for datasets
    
    Options:
      --help  Show this message and exit.
    
    Commands:
      add-files    Add files to the repo
      add-preview  Add files preview from files into metadata
      clone        Clone a git URL
      commit       Commit the changes made to a dataset
      config       Create configuration file (~/.dgit.ini)
      default      Set the default dataset
      diff         Show changes
      drop         Drop a dataset
      init         Bootstrap a new dataset (a git repo+s3...
      list         List datasets
      log          Commit the changes made to a dataset
      plugins      Plugin management
      post         Post to metadata server
      push         Upload a dataset to origin (github/s3/local)
      remote       Manage remote
      rm           Commit the changes made to a dataset
      sh           Post to metadata server
      stash        Trash all the changes for a given dataset
      status       Show all the datasets available
      validate     Check the integrity of a dataset
    

Tutorial
--------

We show how to create a simple dataset that is a git repo with s3 as
the backend. The package itself is flexible enough to support multiple
dataset representations.

Installation:

::

    # Prepare the environment
    virtualenv -p /usr/bin/python3 env
    . env/bin/activate
    
    # install dgit
    pip install dgit
    
    # Initialize the configuration
    dgit config init

Create a dataset repository 

::
    
    # local repo with s3 backup (default)
    dgit init --setup dgit+s3 coupon-assignment
    
Add static files or results of execution 

::

    # Add static files
    dgit add coupon-assignment model-readme.txt m1.json
    
    # Atomatically add files generated by model code
    dgit add coupon-assignment --include "*.csv,*.json" --execute model.py

Commit and push to S3 
::
    
    # commit to local repository
    dgit commit coupon-assignment -m -a  "first run" 
    
    # push to s3 as a backup 
    dgit push coupon-assignment master origin
    
Use the model in production server-side 

::
    
    # Clone the repo to the local workspace
    dgit clone s3://bucket/dgit/pingali/coupon-assignment.dgit
    
    # Check what is in the repo 
    dgit ls coupon-assignment 


Plugins
-------

This is the base set of plugins supported by the default dgit
repo. More extensions are part of `dgit-extensions
<https://github.com/pingali/dgit-extensions>`_.

::

   # The modules in bold are extensions from this repo 
   $ dgit plugins 
   ========
   metadata
   ========
   generic-metadata (v0) : generic-metadata Basic metadata tracker
      Supp: ['generic-metadata']
   
   ========
   validator
   ========
   basic-validator (v0) : basic-validator Basic validator of the content
      Supp: ['basic-validator']
   
   ========
   instrumentation
   ========
   platform (v0) : platform Execution platform information
      Supp: ['platform']
   content (v0) : content Basic content analysis
      Supp: ['content']
   executable (v0) : executable Executable analysis
      Supp: ['executable']
   
   ========
   backend
   ========
   s3 (v0) : s3 S3 backend
      Supp: ['s3']
   local (v0) : local Local filesystem backend
      Supp: ['local']
   
   ========
   repomanager
   ========
   git (v0) : git Git-based repomanager
      Supp: ['git']


Security and Privacy
--------------------

Some basic principles adhered to by dgit: 

1. dgit code is opensource to enable auditing if needed. 

2. No data ever leaves organizational premises (or even local machine)
   without explicit actions.

3. When pushing data repo to a backend such as s3, it is done using
   credentials stored on the local machine. Nobody outside the
   organization can access the repo.

4. When metadata is posted to any server to enable search, lineage
   computation etc. the parameters are controlled - what is posted,
   when and where. 

5. When data leaves premises (e.g., dgit post), it is only metadata by
   default (filenames, timestamps etc). There is an ability to add
   previews/schemas etc but that information must be explicitly
   added. All metadata being posted is stored in a standard location
   (datapackage.json) within the data repo. Posting rawdata is not
   supported by design.


Background
==========

Dataset Management Problem
---------------------------

Some persistent problems of datascientists include: 

* Tracking which dataset was used to generate a result? 
* How did we get to the dataset to begin with? 
* Finding analysis that will be impacted by change in version of a dataset? 

Datascience domain needs a tool that is no more complex than git to
manage these problems that:

* Is simple to deploy and use, and does not impose a certain way of doing
  things.
* Does not require coordination with people if there is only one user,
  but does not prevent coordination and collaboration
* Addresses the needs of dataset versioning including metadata content
  and representation and use of third party versioning or storage
  services such as s3 and instabase.


Usecase
-------

* A single code repo may generate many datasets, each of which may have
  one or more files,  during many runs  
* There are usually large number of small files 
* Datasets are used by non-technical teams including business teams 
* Datasets may be generated outside git repos (e.g., acquisition from
  third party, software such as simulators)
* Datasets may be rawdata or data generator scripts 
* Files may be added to datasets over time
* Datasets may not be able to leave premises 
* Data analysis projects tend to have relatively short duration (1 day
  to few months) and executed by relatively isolated teams (one
  individual to a few). 
* Auditability and shareability is required but sharing is not as
  extensive as software development. People tend to work on different
  business problems.

We could force express these into a one or more git repos, run a git
server locally, and/or use github LFS/gitlab annex. We felt that the
usecase is slightly different from software repos


License 
-------

MIT license. 

Copyright (c) 2016, Venkata Pingali
All rights reserved.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

Contibutors
-----------

`Venkata Pingali <https://github.com/pingali/>`_ (pingali@gmail.com) 
